{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qyaZotPCyoQ8"
   },
   "source": [
    "Install and import packages, mount **drive**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-18T10:41:19.320258Z",
     "iopub.status.busy": "2022-05-18T10:41:19.319907Z",
     "iopub.status.idle": "2022-05-18T10:41:27.548413Z",
     "shell.execute_reply": "2022-05-18T10:41:27.547633Z",
     "shell.execute_reply.started": "2022-05-18T10:41:19.320156Z"
    },
    "id": "ECODTAGzrCRF",
    "outputId": "2bc0e248-631b-4a8f-f705-960f66c36686"
   },
   "outputs": [],
   "source": [
    "# !pip install --user simpletransformers\n",
    "# !pip install --user transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-18T10:41:34.820750Z",
     "iopub.status.busy": "2022-05-18T10:41:34.820469Z",
     "iopub.status.idle": "2022-05-18T10:41:39.314247Z",
     "shell.execute_reply": "2022-05-18T10:41:39.313375Z",
     "shell.execute_reply.started": "2022-05-18T10:41:34.820714Z"
    },
    "id": "UngOggc7o5IO"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import logging\n",
    "import os\n",
    "import random\n",
    "random.seed(0)\n",
    "\n",
    "from simpletransformers.classification import ClassificationModel, ClassificationArgs\n",
    "\n",
    "#from google.colab import drive\n",
    "#drive.mount('/content/gdrive/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_Xi138SaQGG4"
   },
   "source": [
    "# 0. Preparation and definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WPGM4tFuyu7K"
   },
   "source": [
    "**Import the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-18T10:41:39.317413Z",
     "iopub.status.busy": "2022-05-18T10:41:39.317149Z",
     "iopub.status.idle": "2022-05-18T10:41:39.394020Z",
     "shell.execute_reply": "2022-05-18T10:41:39.393176Z",
     "shell.execute_reply.started": "2022-05-18T10:41:39.317378Z"
    },
    "id": "odgdhhJHpo0D"
   },
   "outputs": [],
   "source": [
    "# Import the data\n",
    "cur_dir = os.getcwd()\n",
    "train = pd.read_csv(cur_dir + '/input/olid-data/olid-train.csv')\n",
    "test = pd.read_csv(cur_dir + '/input/olid-data/olid-test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ee1hGi8-zfYw"
   },
   "source": [
    "**Making the evaluation call; precision, recall and F1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-18T10:41:39.398114Z",
     "iopub.status.busy": "2022-05-18T10:41:39.397360Z",
     "iopub.status.idle": "2022-05-18T10:41:39.412840Z",
     "shell.execute_reply": "2022-05-18T10:41:39.412078Z",
     "shell.execute_reply.started": "2022-05-18T10:41:39.398072Z"
    },
    "id": "1VsXpOlwyXmX"
   },
   "outputs": [],
   "source": [
    "def evaluation(df, freq_0, freq_1):\n",
    "    df['TP'] = (df['labels'] == 1) & (df['labels'] == df['predictions'])\n",
    "    df['FN'] = (df['labels'] == 1) & (df['labels'] != df['predictions'])\n",
    "    df['FP'] = (df['labels'] == 0) & (df['labels'] != df['predictions'])\n",
    "    df['TN'] = (df['labels'] == 0) & (df['labels'] == df['predictions'])\n",
    "\n",
    "    precision_1 = sum(df['TP']) / (sum(df['TP']) + sum(df['FP'])) if (sum(df['TP']) + sum(df['FP']) > 0) else 0\n",
    "    precision_0 = sum(df['TN']) / (sum(df['FN']) + sum(df['TN'])) if (sum(df['FN']) + sum(df['TN']) > 0) else 0\n",
    "    precision_avg = np.mean([precision_1, precision_0])\n",
    "    precision_wavg = freq_0 * precision_0 + freq_1 * precision_1\n",
    "\n",
    "    recall_1 = sum(df['TP']) / (sum(df['TP']) + sum(df['FN'])) if (sum(df['TP']) + sum(df['FN']) > 0) else 0\n",
    "    recall_0 = sum(df['TN']) / (sum(df['FP']) + sum(df['TN'])) if (sum(df['TP']) + sum(df['FN']) > 0) else 0\n",
    "    recall_avg = np.mean([recall_1, recall_0])\n",
    "    recall_wavg = freq_0 * recall_0 + freq_1 * recall_1\n",
    "\n",
    "    F1_1 = 2 * (precision_1 * recall_1) / (precision_1 + recall_1) if (precision_1 + recall_1 > 0) else 0\n",
    "    F1_0 = 2 * (precision_0 * recall_0) / (precision_0 + recall_0) if (precision_0 + recall_0 > 0) else 0\n",
    "    F1_avg = np.mean([F1_1, F1_0])\n",
    "    F1_wavg = freq_0 * F1_0 + freq_1 * F1_1\n",
    "\n",
    "    print('metric, class_1, class_0, avg, wavg')\n",
    "    print(\"precision: \", precision_1, precision_0, precision_avg, precision_wavg)\n",
    "    print(\"recall: \", recall_1, recall_0, recall_avg, recall_wavg)\n",
    "    print(\"F1: \", F1_1, F1_0, F1_avg, F1_wavg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rc9IUbpm2tFu"
   },
   "source": [
    "# 1. Class distributions (1 point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-18T10:41:39.414329Z",
     "iopub.status.busy": "2022-05-18T10:41:39.414032Z",
     "iopub.status.idle": "2022-05-18T10:41:39.455862Z",
     "shell.execute_reply": "2022-05-18T10:41:39.455121Z",
     "shell.execute_reply.started": "2022-05-18T10:41:39.414286Z"
    },
    "id": "JuUx7spdyfcA",
    "outputId": "b9c5c141-96c5-4182-9710-2b1b595bddbb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    8840\n",
      "1    4400\n",
      "Name: labels, dtype: int64\n",
      "0    0.667674\n",
      "1    0.332326\n",
      "Name: labels, dtype: float64\n",
      "Amazon is investigating Chinese employees who are selling internal data to third-party sellers looking for an edge in the competitive marketplace. URL #Amazon #MAGA #KAG #CHINA #TCOT\n",
      "@USER She should ask a few native Americans what their take on this is.\n"
     ]
    }
   ],
   "source": [
    "# 1. Class distributions (1 point)\n",
    "print(train['labels'].value_counts())\n",
    "print(train['labels'].value_counts(normalize=True))\n",
    "freq_0 = train['labels'].value_counts(normalize=True).iloc[0]\n",
    "freq_1 = train['labels'].value_counts(normalize=True).iloc[1]\n",
    "print(train[train['labels'] == 0].iloc[0]['text'])\n",
    "print(train[train['labels'] == 1].iloc[0]['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yb29wdsc2YJo"
   },
   "source": [
    "# 2.\tBaselines (1 point) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-18T10:41:39.457590Z",
     "iopub.status.busy": "2022-05-18T10:41:39.457245Z",
     "iopub.status.idle": "2022-05-18T10:41:39.480547Z",
     "shell.execute_reply": "2022-05-18T10:41:39.479649Z",
     "shell.execute_reply.started": "2022-05-18T10:41:39.457538Z"
    },
    "id": "_Oc7Fph02Xpi",
    "outputId": "301c1895-d0a3-4687-f6fc-0dcf0f47ca4d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric, class_1, class_0, avg, wavg\n",
      "precision:  0.26823529411764707 0.7103448275862069 0.48929006085192694 0.5634202092129694\n",
      "recall:  0.475 0.49838709677419357 0.4866935483870968 0.49061494980996007\n",
      "F1:  0.3428571428571429 0.585781990521327 0.4643195666892349 0.5050516786087582\n"
     ]
    }
   ],
   "source": [
    "# Random\n",
    "df_random = test[['text', 'labels']]\n",
    "predictions = []\n",
    "for i in range(len(df_random)):\n",
    "    if random.random() > 0.5:\n",
    "        predictions.append(1)\n",
    "    else:\n",
    "        predictions.append(0)\n",
    "df_random['predictions'] = predictions\n",
    "evaluation(df_random, freq_0, freq_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-18T10:41:39.482319Z",
     "iopub.status.busy": "2022-05-18T10:41:39.481892Z",
     "iopub.status.idle": "2022-05-18T10:41:39.505676Z",
     "shell.execute_reply": "2022-05-18T10:41:39.504947Z",
     "shell.execute_reply.started": "2022-05-18T10:41:39.482281Z"
    },
    "id": "mb_HakG4Jevt",
    "outputId": "8d2f28e2-4d40-40d6-a8d6-19633b9d8ef7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric, class_1, class_0, avg, wavg\n",
      "precision:  0 0.7209302325581395 0.36046511627906974 0.4813461673575493\n",
      "recall:  0.0 1.0 0.5 0.6676737160120846\n",
      "F1:  0 0.8378378378378378 0.4189189189189189 0.5594023026047195\n"
     ]
    }
   ],
   "source": [
    "# Majority\n",
    "df = train[['text', 'labels']]\n",
    "majority_class = df['labels'].value_counts().idxmax()\n",
    "df_majority = test[['text', 'labels']]\n",
    "predictions = [majority_class] * len(df_majority)\n",
    "df_majority['predictions'] = predictions\n",
    "evaluation(df_majority, freq_0, freq_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PRhE8LZKyzdd"
   },
   "source": [
    "# 3.\tClassification by fine-tuning BERT (2.5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-18T10:41:39.507509Z",
     "iopub.status.busy": "2022-05-18T10:41:39.506951Z",
     "iopub.status.idle": "2022-05-18T10:41:39.512409Z",
     "shell.execute_reply": "2022-05-18T10:41:39.511470Z",
     "shell.execute_reply.started": "2022-05-18T10:41:39.507459Z"
    },
    "id": "F2jaai1BsBWi"
   },
   "outputs": [],
   "source": [
    "# # Preparing short train data\n",
    "# train_df_trim = train.iloc[:1000,:][['text','labels']]\n",
    "# # Preparing short eval data\n",
    "# eval_df_trim = train.iloc[1000:1200,:][['text','labels']]\n",
    "# # Preparing short test data\n",
    "# test_df_trim = test.iloc[:100,:][['text','labels']]\n",
    "# test_list_trim = test_df_trim['text'].values.tolist()[:100]\n",
    "\n",
    "# logging.basicConfig(level=logging.INFO)\n",
    "# transformers_logger = logging.getLogger(\"transformers\")\n",
    "# transformers_logger.setLevel(logging.WARNING)\n",
    "\n",
    "# cuda_available = torch.cuda.is_available()\n",
    "# model = ClassificationModel(\n",
    "#     \"bert\", \"bert-base-cased\", use_cuda=cuda_available\n",
    "# )\n",
    "\n",
    "# # Train the model\n",
    "# model.train_model(train_df_trim)\n",
    "\n",
    "# # Evaluate the model\n",
    "# result, model_outputs, wrong_predictions = model.eval_model(eval_df_trim)\n",
    "\n",
    "# # Make predictions with the model\n",
    "# predictions, raw_outputs = model.predict(test_list_trim)\n",
    "\n",
    "# # Attach predictions to test df for evaluation\n",
    "# test_df_trim['predictions'] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-18T10:41:39.514444Z",
     "iopub.status.busy": "2022-05-18T10:41:39.514044Z",
     "iopub.status.idle": "2022-05-18T10:46:07.519825Z",
     "shell.execute_reply": "2022-05-18T10:46:07.518857Z",
     "shell.execute_reply.started": "2022-05-18T10:41:39.514275Z"
    },
    "id": "yAyxR0JczQOh",
    "outputId": "fe12976d-83b0-444c-fd37-b20ae64cb6fa"
   },
   "outputs": [],
   "source": [
    "# # Preparing train data\n",
    "# train_df = train.iloc[:10000,:][['text','labels']] #+/- 80% of the training set\n",
    "# # Preparing eval data\n",
    "# eval_df = train.iloc[10000:,:][['text','labels']] #+/- 20% of the training set\n",
    "# # Preparing test data\n",
    "# test_df = test[['text','labels']]\n",
    "# test_list = test_df['text'].values.tolist()\n",
    "\n",
    "# print(len(train_df))\n",
    "# # print(train_df.head())\n",
    "# # print(len(eval_df))\n",
    "# # print(eval_df.head())\n",
    "# # print(len(test_list))\n",
    "# # print(test_list[:2])\n",
    "\n",
    "# logging.basicConfig(level=logging.INFO)\n",
    "# transformers_logger = logging.getLogger(\"transformers\")\n",
    "# transformers_logger.setLevel(logging.WARNING)\n",
    "\n",
    "# model_args = ClassificationArgs()\n",
    "# model_args.overwrite_output_dir = True\n",
    "\n",
    "# cuda_available = torch.cuda.is_available()\n",
    "# print(cuda_available)\n",
    "# model = ClassificationModel(\n",
    "#     \"bert\", \"bert-base-cased\", use_cuda=cuda_available, args=model_args\n",
    "# )\n",
    "\n",
    "# # Train the model\n",
    "# model.train_model(train_df)\n",
    "\n",
    "# # Evaluate the model\n",
    "# result, model_outputs, wrong_predictions = model.eval_model(eval_df)\n",
    "\n",
    "# # Make predictions with the model\n",
    "# predictions, raw_outputs = model.predict(test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-18T10:46:07.522237Z",
     "iopub.status.busy": "2022-05-18T10:46:07.521893Z",
     "iopub.status.idle": "2022-05-18T10:46:07.555040Z",
     "shell.execute_reply": "2022-05-18T10:46:07.554282Z",
     "shell.execute_reply.started": "2022-05-18T10:46:07.522195Z"
    },
    "id": "DbZzXE8U2FPo"
   },
   "outputs": [],
   "source": [
    "# # Attach predictions to test df for evaluation\n",
    "# test_df['predictions'] = predictions\n",
    "# print(test_df)\n",
    "\n",
    "# # Calculate evaluation metrics\n",
    "# evaluation(test_df, freq_0, freq_1)\n",
    "\n",
    "# print(sum(test_df['predictions'] == test_df['labels']))\n",
    "# print(len(test_df['predictions']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-18T10:46:07.556751Z",
     "iopub.status.busy": "2022-05-18T10:46:07.556422Z",
     "iopub.status.idle": "2022-05-18T10:46:07.563721Z",
     "shell.execute_reply": "2022-05-18T10:46:07.562945Z",
     "shell.execute_reply.started": "2022-05-18T10:46:07.556714Z"
    },
    "id": "jGPvnCLIBdnY"
   },
   "outputs": [],
   "source": [
    "# # Confusion matrix elements\n",
    "# print('TP: ', sum(test_df['TP']))\n",
    "# print('FN: ', sum(test_df['FN']))\n",
    "# print('FP: ', sum(test_df['FP']))\n",
    "# print('TN: ', sum(test_df['TN']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jYXtfF0vNryU"
   },
   "source": [
    "# 4.\tInspect the tokenization of the OLIDv1 training set using the BERT’s tokenizer (2.5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-18T10:46:07.569320Z",
     "iopub.status.busy": "2022-05-18T10:46:07.568739Z",
     "iopub.status.idle": "2022-05-18T10:46:09.673918Z",
     "shell.execute_reply": "2022-05-18T10:46:09.671064Z",
     "shell.execute_reply.started": "2022-05-18T10:46:07.569284Z"
    },
    "id": "yxdTma0INqbZ"
   },
   "outputs": [],
   "source": [
    "# train_text = train['text'].values.tolist()\n",
    "# #print(train_text)\n",
    "# train_tokens = []\n",
    "# for i in range(len(train_text)):\n",
    "#     tokens = model.tokenizer.tokenize(train_text[i])\n",
    "#     train_tokens.extend(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-18T10:46:09.681151Z",
     "iopub.status.busy": "2022-05-18T10:46:09.678922Z",
     "iopub.status.idle": "2022-05-18T10:46:09.745319Z",
     "shell.execute_reply": "2022-05-18T10:46:09.743291Z",
     "shell.execute_reply.started": "2022-05-18T10:46:09.681105Z"
    },
    "id": "x8hq39S4IMwu"
   },
   "outputs": [],
   "source": [
    "# # number of tokens\n",
    "# print(len(train_tokens))\n",
    "\n",
    "# # number of token split into subwords\n",
    "# train_tokens_str = ' '.join(train_tokens)\n",
    "# print(train_tokens_str.count('##'))\n",
    "# train_tokens_str[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-18T10:46:09.747106Z",
     "iopub.status.busy": "2022-05-18T10:46:09.746724Z",
     "iopub.status.idle": "2022-05-18T10:46:09.808522Z",
     "shell.execute_reply": "2022-05-18T10:46:09.807783Z",
     "shell.execute_reply.started": "2022-05-18T10:46:09.747067Z"
    },
    "id": "d8GliiofKYrB"
   },
   "outputs": [],
   "source": [
    "# # How long (in characters) is the longest subword in the BERT’s vocabulary? (0.5 points)\n",
    "# print(max(list(model.tokenizer.vocab.keys()), key=len))\n",
    "# print(len(max(list(model.tokenizer.vocab.keys()), key=len)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
